{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/enxo7899/INM701-Introduction-to-Artificial-Intelligence/blob/main/INM701.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbK6_7Q6T0d1"
      },
      "outputs": [],
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "from sklearn.datasets import fetch_lfw_people\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import tensorflow.keras.utils\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Flatten, Dropout\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn import metrics\n",
        "import io\n",
        "import os\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "h5_file_path1 = './datasets/QuickDrawImages21.h5'\n",
        "h5_file_path2 = './datasets/QuickDrawImages22.h5'\n",
        "h5_file_path3 = './datasets/QuickDrawImages23.h5'\n",
        "h5_file_path4 = './datasets/QuickDrawImages24.h5'\n",
        "h5_file_path5 = './datasets/QuickDrawImages25.h5'\n",
        "\n",
        "desired_images = {\n",
        "    \"202\": \"onion\",\n",
        "    \"204\": \"owl\",\n",
        "    \"208\": \"panda\",\n",
        "    \"212\": \"parrot\",\n",
        "    \"215\": \"pear\",\n",
        "    \"218\": \"penguin\",\n",
        "    \"220\": \"pickup_truck\",\n",
        "    \"221\": \"picture_frame\",\n",
        "    \"222\": \"pig\",\n",
        "    \"223\": \"pillow\",\n",
        "    \"224\": \"pineapple\",\n",
        "    \"226\": \"pliers\",\n",
        "    \"227\": \"police_car\",\n",
        "    \"228\": \"pond\",\n",
        "    \"229\": \"pool\",\n",
        "    \"231\": \"postcard\",\n",
        "    \"232\": \"potato\",\n",
        "    \"235\": \"rabbit\",\n",
        "    \"240\": \"rake\",\n",
        "    \"242\": \"rhinoceros\",\n",
        "    \"243\": \"river\",\n",
        "    \"245\": \"rollerskates\",\n",
        "    \"248\": \"saw\"\n",
        "    }\n",
        "\n",
        "# categories = {\n",
        "#     \"onion\": \"healthyfood\",\n",
        "#     \"owl\": \"bird\",\n",
        "#     \"panda\": \"animal\",\n",
        "#     \"parrot\": \"bird\",\n",
        "#     \"pear\": \"healthyfood\",\n",
        "#     \"penguin\": \"bird\",\n",
        "#     \"pickup_truck\": \"vehicle\",\n",
        "#     \"picture_frame\": \"rectangle\",\n",
        "#     \"pig\": \"animal\",\n",
        "#     \"pillow\": \"rectangle\",\n",
        "#     \"pineapple\": \"healthyfood\",\n",
        "#     \"pliers\": \"tool\",\n",
        "#     \"police_car\": \"vehicle\",\n",
        "#     \"pond\": \"water\",\n",
        "#     \"pool\": \"water\",\n",
        "#     \"postcard\": \"rectangle\",\n",
        "#     \"potato\": \"heatlhyfood\",\n",
        "#     \"rabbit\": \"animal\",\n",
        "#     \"rake\": \"tool\",\n",
        "#     \"rhinoceros\": \"animal\",\n",
        "#     \"river\": \"water\",\n",
        "#     \"rollerskates\": \"vehicle\",\n",
        "#     \"saw\": \"tool\"\n",
        "# }\n",
        "\n",
        "def add_desired_images(file_path, target_range_start, target_range_end, images_per_target, X, y, skip=0):\n",
        "    with h5py.File(file_path, 'r') as h5_file:\n",
        "        if 'images' in h5_file:\n",
        "            images_dataset = h5_file['images']\n",
        "            image_index = 0\n",
        "            for target in range(target_range_start, target_range_end):\n",
        "                if str(target) in desired_images:\n",
        "                    for i in range(images_per_target):\n",
        "                        # figure += 1\n",
        "                        X.append(images_dataset[image_index])\n",
        "                        y.append(target)\n",
        "                        image_index += 1 + skip\n",
        "                else:\n",
        "                    image_index += images_per_target\n",
        "        else:\n",
        "            print(\"Image dataset not found!\")\n",
        "    return(X,y)\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "X,y = add_desired_images(h5_file_path1, 200, 210, 10000, X, y)\n",
        "X,y = add_desired_images(h5_file_path2, 210, 220, 10000, X, y)\n",
        "X,y = add_desired_images(h5_file_path3, 220, 230, 10000, X, y)\n",
        "X,y = add_desired_images(h5_file_path4, 230, 240, 10000, X, y)\n",
        "X,y = add_desired_images(h5_file_path5, 240, 250, 10000, X, y)\n",
        "\n",
        "y = tensorflow.keras.utils.to_categorical(y)\n",
        "\n",
        "# Split into training and test data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25,random_state=42)\n",
        "X_train = np.expand_dims(X_train, axis=3)\n",
        "X_test = np.expand_dims(X_test, axis=3)\n",
        "\n",
        "print(X_train[0][0])\n",
        "\n",
        "num_classes = y.shape[1]\n",
        "save_dir = './'\n",
        "model_name = 'doodle.h5'\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(8, kernel_size=(3, 3), strides=1, padding='same', input_shape=(96, 96, 1)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(X_train,y_train,verbose=2,epochs=12)\n",
        "\n",
        "pred_hot = model.predict(X_test)\n",
        "pred = np.argmax(pred_hot,axis=1)\n",
        "y_compare = np.argmax(y_test,axis=1) \n",
        "score = metrics.accuracy_score(y_compare, pred)\n",
        "\n",
        "print(\"Accuracy score: {}\".format(score))\n",
        "\n",
        "print(pred_hot[:5])\n",
        "print(pred)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOImsqsMAFAUC1oTAJXIsn9",
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
